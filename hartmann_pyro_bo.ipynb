{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hartmann function\n",
    "\n",
    "**Goal**: apply Bayesian Optimisation (BO) strategy to minimize Hartmann function with pyro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "from torch.distributions import constraints, transform_to\n",
    "\n",
    "import pyro\n",
    "import pyro.contrib.gp as gp\n",
    "import pyro.distributions as dist\n",
    "\n",
    "pyro.enable_validation(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 1.3.0.post2\n",
      "pyro: 1.0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"torch:\", torch.__version__)\n",
    "print(\"pyro:\", pyro.__version__)\n",
    "\n",
    "if not pyro.__version__.startswith(\"1\"):\n",
    "    raise ValueError(\"incompatible version of pyro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_number = 444\n",
    "\n",
    "def set_random_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "set_random_seed(seed_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "const_hf_a = torch.tensor([[10.0, 3.0, 17.0, 3.5, 1.7, 8.0],\n",
    "                           [0.05, 10.0, 17.0, 0.1, 8.0, 14.0],\n",
    "                           [3.0, 3.5, 1.7, 10.0, 17.0, 8.0],\n",
    "                           [17.0, 8.0, 0.05, 10.0, 0.1, 14.0]])\n",
    "\n",
    "const_hf_c = torch.tensor([1.0, 1.2, 3.0, 3.2])\n",
    "\n",
    "const_hf_p = torch.tensor([[0.1312, 0.1696, 0.5569, 0.0124, 0.8283, 0.5886], \n",
    "                           [0.2329, 0.4135, 0.8307, 0.3736, 0.1004, 0.9991],\n",
    "                           [0.2348, 0.1451, 0.3522, 0.2883, 0.3047, 0.6650],\n",
    "                           [0.4047, 0.8828, 0.8732, 0.5743, 0.1091, 0.0381]])\n",
    "\n",
    "const_hf_x_min = 0\n",
    "const_hf_x_max = 1\n",
    "\n",
    "def hartmann_func(x):\n",
    "    \"\"\"\n",
    "    Compute Hartmann function\n",
    "    Args:\n",
    "        x - [N, 6] dimensional torch tensor.\n",
    "    Returns:\n",
    "        function value\n",
    "    \"\"\"\n",
    "    \n",
    "    no_dims = x.shape[0]\n",
    "    \n",
    "    result = torch.zeros((no_dims))\n",
    "    \n",
    "    for d in range(no_dims):\n",
    "                \n",
    "        for i in range(4):            \n",
    "            sm = torch.dot(const_hf_a[i], (x[d] - const_hf_p[i])**2)\n",
    "        \n",
    "            result[d] += const_hf_c[i]*torch.exp(-sm)\n",
    "            \n",
    "    return -result\n",
    "\n",
    "# Checking GM\n",
    "assert np.allclose(\n",
    "        hartmann_func(torch.tensor([[0.20169, 0.150011, 0.476874, 0.275332, 0.311652, 0.6573]])).numpy(),\n",
    "        np.array([-3.32237], dtype=np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing BO strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining acquisition function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_confidence_bound(gpmodel, x, kappa=2):\n",
    "    \"\"\"\n",
    "    Lower Confidence Bound (LCB): $\\alpha(x)=\\mu(x) - \\kappa\\sigma(x)$\n",
    "    \n",
    "    \"\"\"\n",
    "    mu, variance = gpmodel(x, full_cov=False, noiseless=False)\n",
    "    sigma = variance.sqrt()\n",
    "    \n",
    "    return mu - kappa * sigma\n",
    "\n",
    "normal_phi = lambda x: torch.exp(-x.pow(2)/2)/np.sqrt(2*np.pi)\n",
    "normal_Phi = lambda x: (1 + torch.erf(x / np.sqrt(2))) / 2\n",
    "\n",
    "def expected_improvement(gpmodel, x):\n",
    "    \"\"\"\n",
    "    Brooks' implementation of expected improvement (EI).\n",
    "    \n",
    "    \"\"\"\n",
    "    y_min = gpmodel.y.min()\n",
    "    \n",
    "    mu, variance = gpmodel(x, full_cov=False, noiseless=False)\n",
    "    \n",
    "    sigma = variance.sqrt()\n",
    "    \n",
    "    delta = y_min - mu\n",
    "    \n",
    "    EI = delta.clamp_min(0.0) + sigma*normal_phi(delta/sigma) - delta.abs()*normal_Phi(delta/sigma)\n",
    "    \n",
    "    return -EI\n",
    "\n",
    "def acquisition_func(gpmodel, x, af='EI'):\n",
    "    \"\"\"\n",
    "    Defines acquisition function.\n",
    "    \"\"\"\n",
    "    \n",
    "    if af == \"EI\":\n",
    "        return expected_improvement(gpmodel, x)\n",
    "    \n",
    "    elif af == \"LCB\":\n",
    "        return lower_confidence_bound(gpmodel, x)\n",
    "    \n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimalistic BO Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to find minimizing points for an acquisition function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_a_candidate(gpmodel, x_init):\n",
    "   \n",
    "    # Creating constrains\n",
    "    constraint_x = constraints.interval(const_hf_x_min, const_hf_x_max)\n",
    "    \n",
    "    # transform x_init to an unconstrained domain as we use an unconstrained optimizer\n",
    "    unconstrained_x1_init = transform_to(constraint_x).inv(x_init[:, 0])\n",
    "    unconstrained_x2_init = transform_to(constraint_x).inv(x_init[:, 1])\n",
    "    unconstrained_x3_init = transform_to(constraint_x).inv(x_init[:, 2])\n",
    "    unconstrained_x4_init = transform_to(constraint_x).inv(x_init[:, 3])\n",
    "    unconstrained_x5_init = transform_to(constraint_x).inv(x_init[:, 4])\n",
    "    unconstrained_x6_init = transform_to(constraint_x).inv(x_init[:, 5])\n",
    "    \n",
    "    x_uncon_init = torch.stack((unconstrained_x1_init, \n",
    "                                unconstrained_x2_init,\n",
    "                                unconstrained_x3_init,\n",
    "                                unconstrained_x4_init,\n",
    "                                unconstrained_x5_init,\n",
    "                                unconstrained_x6_init), dim=1)\n",
    "    \n",
    "    x_uncon = x_uncon_init.clone().detach().requires_grad_(True)\n",
    "    \n",
    "    # unconstrained minimiser\n",
    "    minimizer = optim.Adam([x_uncon])\n",
    "\n",
    "    def closure():\n",
    "        # clear gradients\n",
    "        minimizer.zero_grad()\n",
    "                \n",
    "        x1_tmp = transform_to(constraint_x)(x_uncon[:, 0])\n",
    "        x2_tmp = transform_to(constraint_x)(x_uncon[:, 1])\n",
    "        x3_tmp = transform_to(constraint_x)(x_uncon[:, 2])\n",
    "        x4_tmp = transform_to(constraint_x)(x_uncon[:, 3])\n",
    "        x5_tmp = transform_to(constraint_x)(x_uncon[:, 4])\n",
    "        x6_tmp = transform_to(constraint_x)(x_uncon[:, 5])\n",
    "        \n",
    "        x = torch.stack((x1_tmp, x2_tmp, x3_tmp, x4_tmp, x5_tmp, x6_tmp), dim=1)\n",
    "        \n",
    "        y = acquisition_func(gpmodel, x)\n",
    "        \n",
    "        autograd.backward(x_uncon, autograd.grad(y, x_uncon))\n",
    "                \n",
    "        return y\n",
    "    \n",
    "    for _ in range(100):\n",
    "        minimizer.step(closure)\n",
    "        \n",
    "    # after finding a candidate in the unconstrained domain,\n",
    "    # convert it back to original domain.\n",
    "    x1_tmp = transform_to(constraint_x)(x_uncon[:, 0])\n",
    "    x2_tmp = transform_to(constraint_x)(x_uncon[:, 1])\n",
    "    x3_tmp = transform_to(constraint_x)(x_uncon[:, 2])\n",
    "    x4_tmp = transform_to(constraint_x)(x_uncon[:, 3])\n",
    "    x5_tmp = transform_to(constraint_x)(x_uncon[:, 4])\n",
    "    x6_tmp = transform_to(constraint_x)(x_uncon[:, 5])\n",
    "    \n",
    "    x = torch.stack((x1_tmp, x2_tmp, x3_tmp, x4_tmp, x5_tmp, x6_tmp), dim=1)\n",
    "    \n",
    "    return x.detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A single step of BO\n",
    "\n",
    "LBFGS optimiser used in `find_a_candidate` is a gradient based method and can get stuck at a local minimum. A simple approach to address this is to try several attemps (5) to find the best candidate to minimize the acquisition function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_x(gpmodel, num_candidates=5):\n",
    "    \n",
    "    candidates = []\n",
    "    values = []\n",
    "    \n",
    "    # take the best (lowest) point as the first attempt\n",
    "    x_init = gpmodel.X[[gpmodel.y.argmin()], :].detach().requires_grad_(True)\n",
    "        \n",
    "    for i in range(num_candidates):\n",
    "        \n",
    "        x = find_a_candidate(gpmodel, x_init)\n",
    "        y = acquisition_func(gpmodel, x)\n",
    "    \n",
    "        candidates.append(x)\n",
    "        values.append(y)\n",
    "        \n",
    "        # a new random attempt initial point\n",
    "        x_init = torch.stack((\n",
    "                    x[:,0].new_empty(1).uniform_(const_hf_x_min, const_hf_x_max),\n",
    "                    x[:,1].new_empty(1).uniform_(const_hf_x_min, const_hf_x_max),\n",
    "                    x[:,2].new_empty(1).uniform_(const_hf_x_min, const_hf_x_max),\n",
    "                    x[:,3].new_empty(1).uniform_(const_hf_x_min, const_hf_x_max),\n",
    "                    x[:,4].new_empty(1).uniform_(const_hf_x_min, const_hf_x_max),\n",
    "                    x[:,5].new_empty(1).uniform_(const_hf_x_min, const_hf_x_max)), dim=1)\n",
    "    \n",
    "        print(\"Candidate \", i, x, y)\n",
    "        \n",
    "    argmin = torch.min(torch.cat(values), dim=0)[1].item()\n",
    "    \n",
    "    print(\"Result: \", candidates[argmin], values[argmin])\n",
    "    \n",
    "    return candidates[argmin], candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating posterior\n",
    "\n",
    "Each time we evaluate `f` at a new value x, we update the `gpmodel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_posterior(gpmodel, x_new, svi_mode=False):\n",
    "        \n",
    "    # evaluate f at new point\n",
    "    bh_y = hartmann_func(x_new) \n",
    "    \n",
    "    # incorporate new evaluation\n",
    "    X = torch.cat([gpmodel.X, x_new]) \n",
    "    y = torch.cat([gpmodel.y, bh_y])\n",
    "        \n",
    "    gpmodel.set_data(X, y)\n",
    "    \n",
    "    # optimising hyper paramters\n",
    "    \n",
    "    optimiser = torch.optim.Adam(gpmodel.parameters(), lr=0.001)\n",
    "    \n",
    "    if svi_mode:\n",
    "        loss_fn = pyro.infer.TraceMeanField_ELBO().differentiable_loss\n",
    "        gp.util.train(gpmodel, optimiser, loss_fn, num_steps=2000)\n",
    "    else:\n",
    "        gp.util.train(gpmodel, optimiser) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cnt = 30\n",
    "\n",
    "X_train = torch.rand(train_cnt, 6)\n",
    "Y_train = hartmann_func(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deterministic approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "BO STEP:  0\n",
      "--------------------------------------------------\n",
      "Candidate  0 tensor([[0.4310, 0.7526, 0.3725, 0.7096, 0.6665, 0.0046]]) tensor([-0.0016], grad_fn=<NegBackward>)\n",
      "Candidate  1 tensor([[0.0753, 0.8654, 0.5869, 0.7903, 0.3471, 0.1851]]) tensor([-0.0010], grad_fn=<NegBackward>)\n",
      "Candidate  2 tensor([[0.5416, 0.9229, 0.3689, 0.6293, 0.3431, 0.3446]]) tensor([-0.0008], grad_fn=<NegBackward>)\n",
      "Candidate  3 tensor([[0.7392, 0.1793, 0.9383, 0.8214, 0.8374, 0.3040]]) tensor([-0.0004], grad_fn=<NegBackward>)\n",
      "Candidate  4 tensor([[0.5888, 0.4643, 0.1963, 0.1713, 0.4578, 0.9334]]) tensor([-0.0003], grad_fn=<NegBackward>)\n",
      "Result:  tensor([[0.4310, 0.7526, 0.3725, 0.7096, 0.6665, 0.0046]]) tensor([-0.0016], grad_fn=<NegBackward>)\n",
      "--------------------------------------------------\n",
      "BO STEP:  1\n",
      "--------------------------------------------------\n",
      "Candidate  0 tensor([[0.4335, 0.7709, 0.3491, 0.7302, 0.6886, 0.0042]]) tensor([-0.0210], grad_fn=<NegBackward>)\n",
      "Candidate  1 tensor([[0.3524, 0.9455, 0.0772, 0.0448, 0.5562, 0.6994]]) tensor([-0.0004], grad_fn=<NegBackward>)\n",
      "Candidate  2 tensor([[0.7360, 0.3322, 0.9543, 0.9403, 0.9384, 0.3659]]) tensor([-4.4394e-08], grad_fn=<NegBackward>)\n",
      "Candidate  3 tensor([[0.9648, 0.5656, 0.4927, 0.2642, 0.9839, 0.0816]]) tensor([-8.8678e-08], grad_fn=<NegBackward>)\n",
      "Candidate  4 tensor([[0.8025, 0.8409, 0.4693, 0.7150, 0.2886, 0.0354]]) tensor([-2.8049e-06], grad_fn=<NegBackward>)\n",
      "Result:  tensor([[0.4335, 0.7709, 0.3491, 0.7302, 0.6886, 0.0042]]) tensor([-0.0210], grad_fn=<NegBackward>)\n",
      "--------------------------------------------------\n",
      "BO STEP:  2\n",
      "--------------------------------------------------\n",
      "Candidate  0 tensor([[0.4339, 0.7712, 0.3487, 0.7304, 0.6424, 0.0042]]) tensor([-0.0578], grad_fn=<NegBackward>)\n",
      "Candidate  1 tensor([[0.7781, 0.1143, 0.5511, 0.4015, 0.6037, 0.8240]]) tensor([-3.1681e-12], grad_fn=<NegBackward>)\n",
      "Candidate  2 tensor([[0.3426, 0.2579, 0.3260, 0.6565, 0.3107, 0.5287]]) tensor([-0.0049], grad_fn=<NegBackward>)\n",
      "Candidate  3 tensor([[0.9525, 0.9792, 0.7727, 0.5695, 0.3511, 0.0760]]) tensor([-1.1421e-11], grad_fn=<NegBackward>)\n",
      "Candidate  4 tensor([[0.3376, 0.2688, 0.7678, 0.7394, 0.0158, 0.4003]]) tensor([-1.8586e-12], grad_fn=<NegBackward>)\n",
      "Result:  tensor([[0.4339, 0.7712, 0.3487, 0.7304, 0.6424, 0.0042]]) tensor([-0.0578], grad_fn=<NegBackward>)\n",
      "--------------------------------------------------\n",
      "BO STEP:  3\n",
      "--------------------------------------------------\n",
      "Candidate  0 tensor([[0.4365, 0.7717, 0.3480, 0.7310, 0.6417, 0.0042]]) tensor([-0.0506], grad_fn=<NegBackward>)\n",
      "Candidate  1 tensor([[0.9453, 0.9291, 0.8527, 0.5304, 0.8724, 0.0085]]) tensor([-1.1268e-23], grad_fn=<NegBackward>)\n",
      "Candidate  2 tensor([[0.5693, 0.2427, 0.1222, 0.8246, 0.8030, 0.2833]]) tensor([-0.0009], grad_fn=<NegBackward>)\n",
      "Candidate  3 tensor([[0.7689, 0.2809, 0.9520, 0.2538, 0.2535, 0.3319]]) tensor([-2.4955e-24], grad_fn=<NegBackward>)\n",
      "Candidate  4 tensor([[0.4535, 0.5476, 0.0682, 0.5516, 0.5435, 0.7306]]) tensor([-0.0574], grad_fn=<NegBackward>)\n",
      "Result:  tensor([[0.4535, 0.5476, 0.0682, 0.5516, 0.5435, 0.7306]]) tensor([-0.0574], grad_fn=<NegBackward>)\n",
      "--------------------------------------------------\n",
      "BO STEP:  4\n",
      "--------------------------------------------------\n",
      "Candidate  0 tensor([[0.4291, 0.7722, 0.3476, 0.7314, 0.6902, 0.0042]]) tensor([-0.0387], grad_fn=<NegBackward>)\n",
      "Candidate  1 tensor([[0.6533, 0.2411, 0.7012, 0.2731, 0.8365, 0.9174]]) tensor([-3.0358e-17], grad_fn=<NegBackward>)\n",
      "Candidate  2 tensor([[0.3966, 0.9313, 0.7703, 0.1385, 0.6846, 0.9146]]) tensor([-2.1130e-16], grad_fn=<NegBackward>)\n",
      "Candidate  3 tensor([[0.4721, 0.0391, 0.6780, 0.1880, 0.6504, 0.9945]]) tensor([-1.2715e-14], grad_fn=<NegBackward>)\n",
      "Candidate  4 tensor([[0.0723, 0.1638, 0.4855, 0.5772, 0.7048, 0.2869]]) tensor([-6.5568e-30], grad_fn=<NegBackward>)\n",
      "Result:  tensor([[0.4291, 0.7722, 0.3476, 0.7314, 0.6902, 0.0042]]) tensor([-0.0387], grad_fn=<NegBackward>)\n",
      "--------------------------------------------------\n",
      "BO STEP:  5\n",
      "--------------------------------------------------\n",
      "Candidate  0 tensor([[0.4557, 0.7739, 0.3448, 0.7342, 0.6936, 0.0041]]) tensor([-0.0301], grad_fn=<NegBackward>)\n",
      "Candidate  1 tensor([[0.7133, 0.0388, 0.3327, 0.6370, 0.9232, 0.2279]]) tensor([-3.1293e-11], grad_fn=<NegBackward>)\n",
      "Candidate  2 tensor([[0.9826, 0.7738, 0.7970, 0.5624, 0.4205, 0.8674]]) tensor([-2.7402e-27], grad_fn=<NegBackward>)\n",
      "Candidate  3 tensor([[0.4997, 0.1383, 0.1682, 0.3641, 0.1134, 0.3461]]) tensor([-6.5424e-05], grad_fn=<NegBackward>)\n",
      "Candidate  4 tensor([[0.4137, 0.3008, 0.6706, 0.7721, 0.9920, 0.8216]]) tensor([-4.3840e-14], grad_fn=<NegBackward>)\n",
      "Result:  tensor([[0.4557, 0.7739, 0.3448, 0.7342, 0.6936, 0.0041]]) tensor([-0.0301], grad_fn=<NegBackward>)\n",
      "--------------------------------------------------\n",
      "BO STEP:  6\n",
      "--------------------------------------------------\n",
      "Candidate  0 tensor([[0.4283, 0.7719, 0.3477, 0.7283, 0.6423, 0.0042]]) tensor([-0.0179], grad_fn=<NegBackward>)\n",
      "Candidate  1 tensor([[0.2549, 0.5262, 0.1353, 0.6243, 0.8511, 0.5454]]) tensor([-2.5907e-08], grad_fn=<NegBackward>)\n",
      "Candidate  2 tensor([[0.6785, 0.0241, 0.0369, 0.6092, 0.8493, 0.8906]]) tensor([-2.2704e-12], grad_fn=<NegBackward>)\n",
      "Candidate  3 tensor([[0.9543, 0.2702, 0.1451, 0.0379, 0.1155, 0.5692]]) tensor([-2.2170e-16], grad_fn=<NegBackward>)\n",
      "Candidate  4 tensor([[0.8397, 0.9648, 0.4435, 0.2694, 0.9942, 0.2581]]) tensor([-5.1611e-27], grad_fn=<NegBackward>)\n",
      "Result:  tensor([[0.4283, 0.7719, 0.3477, 0.7283, 0.6423, 0.0042]]) tensor([-0.0179], grad_fn=<NegBackward>)\n",
      "--------------------------------------------------\n",
      "BO STEP:  7\n",
      "--------------------------------------------------\n",
      "Candidate  0 tensor([[0.4258, 0.7692, 0.3513, 0.6919, 0.6409, 0.0042]]) tensor([-0.0093], grad_fn=<NegBackward>)\n",
      "Candidate  1 tensor([[6.7528e-01, 4.1716e-01, 7.7831e-01, 4.3881e-01, 3.6353e-04, 6.8870e-01]]) tensor([-8.9689e-17], grad_fn=<NegBackward>)\n",
      "Candidate  2 tensor([[0.0325, 0.7621, 0.1285, 0.3378, 0.4317, 0.9877]]) tensor([-2.3911e-15], grad_fn=<NegBackward>)\n",
      "Candidate  3 tensor([[0.0977, 0.7070, 0.9326, 0.6330, 0.7559, 0.4509]]) tensor([-2.1288e-11], grad_fn=<NegBackward>)\n",
      "Candidate  4 tensor([[0.4084, 0.9590, 0.7348, 0.3775, 0.5437, 0.0772]]) tensor([-1.0246e-36], grad_fn=<NegBackward>)\n",
      "Result:  tensor([[0.4258, 0.7692, 0.3513, 0.6919, 0.6409, 0.0042]]) tensor([-0.0093], grad_fn=<NegBackward>)\n",
      "--------------------------------------------------\n",
      "BO STEP:  8\n",
      "--------------------------------------------------\n",
      "Candidate  0 tensor([[0.4018, 0.7795, 0.3243, 0.6860, 0.6117, 0.0037]]) tensor([-0.0043], grad_fn=<NegBackward>)\n",
      "Candidate  1 tensor([[0.7007, 0.8504, 0.3231, 0.4265, 0.7264, 0.7793]]) tensor([-0.], grad_fn=<NegBackward>)\n",
      "Candidate  2 tensor([[0.4741, 0.5956, 0.9074, 0.4020, 0.0716, 0.3775]]) tensor([-3.7908e-16], grad_fn=<NegBackward>)\n",
      "Candidate  3 tensor([[0.4967, 0.0180, 0.7454, 0.8341, 0.8778, 0.8417]]) tensor([-9.8047e-41], grad_fn=<NegBackward>)\n",
      "Candidate  4 tensor([[0.6760, 0.3257, 0.7641, 0.1619, 0.3972, 0.1816]]) tensor([-1.2452e-27], grad_fn=<NegBackward>)\n",
      "Result:  tensor([[0.4018, 0.7795, 0.3243, 0.6860, 0.6117, 0.0037]]) tensor([-0.0043], grad_fn=<NegBackward>)\n",
      "--------------------------------------------------\n",
      "BO STEP:  9\n",
      "--------------------------------------------------\n",
      "Candidate  0 tensor([[0.3858, 0.7896, 0.3009, 0.6815, 0.5856, 0.0033]]) tensor([-0.0170], grad_fn=<NegBackward>)\n",
      "Candidate  1 tensor([[0.3137, 0.1937, 0.1197, 0.0759, 0.1804, 0.2723]]) tensor([-0.0004], grad_fn=<NegBackward>)\n",
      "Candidate  2 tensor([[0.5302, 0.8348, 0.4073, 0.0344, 0.7346, 0.5359]]) tensor([-1.0381e-15], grad_fn=<NegBackward>)\n",
      "Candidate  3 tensor([[0.5502, 0.6264, 0.0880, 0.8940, 0.0570, 0.2354]]) tensor([-3.5342e-07], grad_fn=<NegBackward>)\n",
      "Candidate  4 tensor([[5.1957e-03, 9.0985e-01, 3.2765e-04, 4.3034e-01, 8.1038e-01, 2.1205e-02]]) tensor([-3.5733e-06], grad_fn=<NegBackward>)\n",
      "Result:  tensor([[0.3858, 0.7896, 0.3009, 0.6815, 0.5856, 0.0033]]) tensor([-0.0170], grad_fn=<NegBackward>)\n",
      "--------------------------------------------------\n",
      "BO STEP:  10\n",
      "--------------------------------------------------\n",
      "Candidate  0 tensor([[0.3797, 0.7961, 0.2794, 0.6784, 0.5599, 0.0030]]) tensor([-0.0341], grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate  1 tensor([[0.9265, 0.2576, 0.3642, 0.1772, 0.3089, 0.9994]]) tensor([-7.4444e-19], grad_fn=<NegBackward>)\n",
      "Candidate  2 tensor([[0.3462, 0.8991, 0.3599, 0.6164, 0.2959, 0.7436]]) tensor([-1.3918e-13], grad_fn=<NegBackward>)\n",
      "Candidate  3 tensor([[0.2846, 0.4429, 0.1432, 0.0341, 0.6348, 0.0013]]) tensor([-0.0234], grad_fn=<NegBackward>)\n",
      "Candidate  4 tensor([[0.4674, 0.8096, 0.9618, 0.9360, 0.5053, 0.5390]]) tensor([-5.2337e-18], grad_fn=<NegBackward>)\n",
      "Result:  tensor([[0.3797, 0.7961, 0.2794, 0.6784, 0.5599, 0.0030]]) tensor([-0.0341], grad_fn=<NegBackward>)\n",
      "--------------------------------------------------\n",
      "BO STEP:  11\n",
      "--------------------------------------------------\n",
      "Candidate  0 tensor([[0.3785, 0.7990, 0.2593, 0.6771, 0.5341, 0.0027]]) tensor([-0.0486], grad_fn=<NegBackward>)\n",
      "Candidate  1 tensor([[0.8064, 0.7688, 0.8100, 0.3800, 0.1871, 0.6969]]) tensor([-1.1308e-29], grad_fn=<NegBackward>)\n",
      "Candidate  2 tensor([[0.3730, 0.0993, 0.3069, 0.4249, 0.4430, 0.6283]]) tensor([-3.7875e-14], grad_fn=<NegBackward>)\n",
      "Candidate  3 tensor([[0.3433, 0.1956, 0.1755, 0.2595, 0.1098, 0.0677]]) tensor([-0.0407], grad_fn=<NegBackward>)\n",
      "Candidate  4 tensor([[0.0679, 0.0408, 0.1445, 0.5131, 0.9044, 0.0516]]) tensor([-5.5658e-08], grad_fn=<NegBackward>)\n",
      "Result:  tensor([[0.3785, 0.7990, 0.2593, 0.6771, 0.5341, 0.0027]]) tensor([-0.0486], grad_fn=<NegBackward>)\n",
      "--------------------------------------------------\n",
      "BO STEP:  12\n",
      "--------------------------------------------------\n",
      "Candidate  0 tensor([[0.3773, 0.7998, 0.2419, 0.6766, 0.5104, 0.0025]]) tensor([-0.0546], grad_fn=<NegBackward>)\n",
      "Candidate  1 tensor([[0.3080, 0.9556, 0.8807, 0.2625, 0.7327, 0.2761]]) tensor([-4.5140e-23], grad_fn=<NegBackward>)\n",
      "Candidate  2 tensor([[0.1206, 0.3726, 0.2512, 0.9280, 0.3864, 0.6453]]) tensor([-0.], grad_fn=<NegBackward>)\n",
      "Candidate  3 tensor([[0.6600, 0.6496, 0.8021, 0.9227, 0.4879, 0.7178]]) tensor([-8.1260e-32], grad_fn=<NegBackward>)\n",
      "Candidate  4 tensor([[0.4798, 0.5986, 0.9376, 0.3874, 0.7323, 0.7080]]) tensor([-6.9584e-34], grad_fn=<NegBackward>)\n",
      "Result:  tensor([[0.3773, 0.7998, 0.2419, 0.6766, 0.5104, 0.0025]]) tensor([-0.0546], grad_fn=<NegBackward>)\n",
      "--------------------------------------------------\n",
      "BO STEP:  13\n",
      "--------------------------------------------------\n",
      "Candidate  0 tensor([[0.3771, 0.8000, 0.2261, 0.6766, 0.4875, 0.0023]]) tensor([-0.0556], grad_fn=<NegBackward>)\n",
      "Candidate  1 tensor([[0.8168, 0.6735, 0.6333, 0.5033, 0.6594, 0.1603]]) tensor([-5.9854e-28], grad_fn=<NegBackward>)\n",
      "Candidate  2 tensor([[0.3256, 0.4027, 0.8203, 0.1176, 0.8817, 0.3786]]) tensor([-6.6281e-39], grad_fn=<NegBackward>)\n",
      "Candidate  3 tensor([[0.5119, 0.0957, 0.2202, 0.9620, 0.3042, 0.8717]]) tensor([-4.4270e-23], grad_fn=<NegBackward>)\n",
      "Candidate  4 tensor([[0.0010, 0.8340, 0.2679, 0.7555, 0.7696, 0.8925]]) tensor([-1.0254e-15], grad_fn=<NegBackward>)\n",
      "Result:  tensor([[0.3771, 0.8000, 0.2261, 0.6766, 0.4875, 0.0023]]) tensor([-0.0556], grad_fn=<NegBackward>)\n",
      "--------------------------------------------------\n",
      "BO STEP:  14\n",
      "--------------------------------------------------\n",
      "Candidate  0 tensor([[0.3848, 0.8000, 0.2107, 0.6765, 0.4632, 0.0021]]) tensor([-0.0543], grad_fn=<NegBackward>)\n",
      "Candidate  1 tensor([[0.4318, 0.7488, 0.2582, 0.6248, 0.4239, 0.3531]]) tensor([-2.0858e-07], grad_fn=<NegBackward>)\n",
      "Candidate  2 tensor([[0.3893, 0.9400, 0.6700, 0.2037, 0.5490, 0.8064]]) tensor([-1.2159e-20], grad_fn=<NegBackward>)\n",
      "Candidate  3 tensor([[0.5161, 0.9012, 0.2246, 0.7438, 0.7388, 0.9132]]) tensor([-4.4780e-20], grad_fn=<NegBackward>)\n",
      "Candidate  4 tensor([[0.7958, 0.2559, 0.0191, 0.1016, 0.7224, 0.8647]]) tensor([-1.9672e-18], grad_fn=<NegBackward>)\n",
      "Result:  tensor([[0.3848, 0.8000, 0.2107, 0.6765, 0.4632, 0.0021]]) tensor([-0.0543], grad_fn=<NegBackward>)\n",
      "--------------------------------------------------\n",
      "BO STEP:  15\n",
      "--------------------------------------------------\n",
      "Candidate  0 tensor([[0.3810, 0.8000, 0.1957, 0.6765, 0.4398, 0.0019]]) tensor([-0.0501], grad_fn=<NegBackward>)\n",
      "Candidate  1 tensor([[0.2959, 0.7542, 0.2657, 0.9843, 0.7694, 0.8968]]) tensor([-6.9740e-12], grad_fn=<NegBackward>)\n",
      "Candidate  2 tensor([[0.3520, 0.9357, 0.8235, 0.1955, 0.6893, 0.8485]]) tensor([-2.3918e-21], grad_fn=<NegBackward>)\n",
      "Candidate  3 tensor([[0.2508, 0.1251, 0.8569, 0.1539, 0.2232, 0.8790]]) tensor([-4.4460e-16], grad_fn=<NegBackward>)\n",
      "Candidate  4 tensor([[0.3829, 0.2233, 0.5570, 0.1895, 0.9138, 0.1467]]) tensor([-7.6819e-18], grad_fn=<NegBackward>)\n",
      "Result:  tensor([[0.3810, 0.8000, 0.1957, 0.6765, 0.4398, 0.0019]]) tensor([-0.0501], grad_fn=<NegBackward>)\n",
      "--------------------------------------------------\n",
      "BO STEP:  16\n",
      "--------------------------------------------------\n",
      "Candidate  0 tensor([[0.3800, 0.8000, 0.1959, 0.6765, 0.4403, 0.0019]]) tensor([-0.0441], grad_fn=<NegBackward>)\n",
      "Candidate  1 tensor([[0.6204, 0.2039, 0.0304, 0.0605, 0.3372, 0.6609]]) tensor([-1.8320e-16], grad_fn=<NegBackward>)\n",
      "Candidate  2 tensor([[0.6655, 0.7364, 0.2248, 0.2556, 0.3469, 0.6118]]) tensor([-4.6881e-27], grad_fn=<NegBackward>)\n",
      "Candidate  3 tensor([[0.6462, 0.5970, 0.6740, 0.4040, 0.2798, 0.3829]]) tensor([-0.], grad_fn=<NegBackward>)\n",
      "Candidate  4 tensor([[0.6014, 0.6729, 0.9148, 0.9331, 0.7562, 0.9269]]) tensor([-8.9405e-22], grad_fn=<NegBackward>)\n",
      "Result:  tensor([[0.3800, 0.8000, 0.1959, 0.6765, 0.4403, 0.0019]]) tensor([-0.0441], grad_fn=<NegBackward>)\n",
      "--------------------------------------------------\n",
      "BO STEP:  17\n",
      "--------------------------------------------------\n",
      "Candidate  0 tensor([[0.3793, 0.8000, 0.1960, 0.6765, 0.4404, 0.0019]]) tensor([-0.0396], grad_fn=<NegBackward>)\n",
      "Candidate  1 tensor([[0.1481, 0.0930, 0.0726, 0.8707, 0.5782, 0.9242]]) tensor([-5.5098e-14], grad_fn=<NegBackward>)\n",
      "Candidate  2 tensor([[0.2376, 0.2994, 0.5070, 0.1061, 0.9197, 0.2833]]) tensor([-8.7064e-30], grad_fn=<NegBackward>)\n",
      "Candidate  3 tensor([[0.5668, 0.1638, 0.3380, 0.1653, 0.4236, 0.8775]]) tensor([-1.0875e-21], grad_fn=<NegBackward>)\n",
      "Candidate  4 tensor([[0.3809, 0.2964, 0.0792, 0.3267, 0.9248, 0.1817]]) tensor([-0.0024], grad_fn=<NegBackward>)\n",
      "Result:  tensor([[0.3793, 0.8000, 0.1960, 0.6765, 0.4404, 0.0019]]) tensor([-0.0396], grad_fn=<NegBackward>)\n",
      "--------------------------------------------------\n",
      "BO STEP:  18\n",
      "--------------------------------------------------\n",
      "Candidate  0 tensor([[0.3786, 0.8000, 0.1960, 0.6765, 0.4399, 0.0019]]) tensor([-0.0360], grad_fn=<NegBackward>)\n",
      "Candidate  1 tensor([[0.5178, 0.2025, 0.8804, 0.7143, 0.9841, 0.5177]]) tensor([-1.9677e-24], grad_fn=<NegBackward>)\n",
      "Candidate  2 tensor([[0.3787, 0.3957, 0.8203, 0.4552, 0.8928, 0.5309]]) tensor([-0.], grad_fn=<NegBackward>)\n",
      "Candidate  3 tensor([[0.8388, 0.7892, 0.0308, 0.3138, 0.4899, 0.1203]]) tensor([-1.4580e-24], grad_fn=<NegBackward>)\n",
      "Candidate  4 tensor([[0.3598, 0.3154, 0.2811, 0.4575, 0.1295, 0.7984]]) tensor([-6.2671e-15], grad_fn=<NegBackward>)\n",
      "Result:  tensor([[0.3786, 0.8000, 0.1960, 0.6765, 0.4399, 0.0019]]) tensor([-0.0360], grad_fn=<NegBackward>)\n",
      "--------------------------------------------------\n",
      "BO STEP:  19\n",
      "--------------------------------------------------\n",
      "Candidate  0 tensor([[0.3780, 0.8000, 0.1962, 0.6765, 0.4395, 0.0019]]) tensor([-0.0327], grad_fn=<NegBackward>)\n",
      "Candidate  1 tensor([[0.1581, 0.4749, 0.7587, 0.9905, 0.9860, 0.7496]]) tensor([-6.5549e-17], grad_fn=<NegBackward>)\n",
      "Candidate  2 tensor([[0.3346, 0.3995, 0.0230, 0.4961, 0.0515, 0.1475]]) tensor([-0.0023], grad_fn=<NegBackward>)\n",
      "Candidate  3 tensor([[0.7701, 0.6613, 0.4977, 0.8301, 0.6599, 0.7719]]) tensor([-1.0868e-41], grad_fn=<NegBackward>)\n",
      "Candidate  4 tensor([[0.7740, 0.2881, 0.6753, 0.2659, 0.0744, 0.8639]]) tensor([-4.3813e-18], grad_fn=<NegBackward>)\n",
      "Result:  tensor([[0.3780, 0.8000, 0.1962, 0.6765, 0.4395, 0.0019]]) tensor([-0.0327], grad_fn=<NegBackward>)\n"
     ]
    }
   ],
   "source": [
    "set_random_seed(333)\n",
    "\n",
    "gp_model = gp.models.GPRegression(X_train, Y_train, \n",
    "    gp.kernels.Matern52(input_dim=6, lengthscale=torch.ones(6)))\n",
    "\n",
    "optimizer = torch.optim.Adam(gp_model.parameters(), lr=0.001)\n",
    "losses = gp.util.train(gp_model, optimizer);\n",
    "\n",
    "bo_steps = 20\n",
    "\n",
    "for i in range(bo_steps):\n",
    "    print(\"-\"*50)\n",
    "    print(\"BO STEP: \", i)\n",
    "    print(\"-\"*50)\n",
    "    \n",
    "    gp_model_ = copy.copy(gp_model)\n",
    "    \n",
    "    xmin, xcans = next_x(gp_model)\n",
    "    \n",
    "    update_posterior(gp_model, xmin)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/pyro/infer/trace_mean_field_elbo.py:29: UserWarning: Failed to verify mean field restriction on the guide. To eliminate this warning, ensure model and guide sites occur in the same order.\n",
      "Model sites:\n",
      "  kernel.lengthscale\n",
      "  kernel.variance\n",
      "  noiseGuide sites:\n",
      "  noise\n",
      "  kernel.lengthscale\n",
      "  kernel.variance\n",
      "  \"Guide sites:\\n  \" + \"\\n  \".join(guide_sites))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "BO STEP:  0\n",
      "--------------------------------------------------\n",
      "Candidate  0 tensor([[0.4699, 0.7447, 0.3841, 0.6920, 0.6353, 0.0048]]) tensor([-0.0353], grad_fn=<NegBackward>)\n",
      "Candidate  1 tensor([[0.4679, 0.3049, 0.5816, 0.2563, 0.4632, 0.0345]]) tensor([-1.2469e-07], grad_fn=<NegBackward>)\n",
      "Candidate  2 tensor([[0.4056, 0.3312, 0.2102, 0.7912, 0.8868, 0.6790]]) tensor([-6.7885e-06], grad_fn=<NegBackward>)\n",
      "Candidate  3 tensor([[2.7676e-01, 3.9869e-04, 7.8953e-01, 3.4166e-02, 3.5278e-01, 8.9763e-01]]) tensor([-4.0613e-06], grad_fn=<NegBackward>)\n",
      "Candidate  4 tensor([[0.6033, 0.5760, 0.0712, 0.6738, 0.8409, 0.3037]]) tensor([-6.9344e-06], grad_fn=<NegBackward>)\n",
      "Result:  tensor([[0.4699, 0.7447, 0.3841, 0.6920, 0.6353, 0.0048]]) tensor([-0.0353], grad_fn=<NegBackward>)\n",
      "--------------------------------------------------\n",
      "BO STEP:  1\n",
      "--------------------------------------------------\n",
      "Candidate  0 tensor([[0.4695, 0.7458, 0.3775, 0.6907, 0.6286, 0.0048]]) tensor([-0.0060], grad_fn=<NegBackward>)\n",
      "Candidate  1 tensor([[0.0950, 0.9462, 0.5474, 0.6585, 0.1137, 0.2832]]) tensor([-2.8190e-08], grad_fn=<NegBackward>)\n",
      "Candidate  2 tensor([[0.3276, 0.4032, 0.5708, 0.1720, 0.6360, 0.6977]]) tensor([-1.1681e-05], grad_fn=<NegBackward>)\n",
      "Candidate  3 tensor([[0.3462, 0.7553, 0.8634, 0.0397, 0.3184, 0.4886]]) tensor([-0.0002], grad_fn=<NegBackward>)\n",
      "Candidate  4 tensor([[0.4711, 0.7963, 0.3042, 0.4004, 0.2154, 0.8519]]) tensor([-2.6126e-06], grad_fn=<NegBackward>)\n",
      "Result:  tensor([[0.4695, 0.7458, 0.3775, 0.6907, 0.6286, 0.0048]]) tensor([-0.0060], grad_fn=<NegBackward>)\n",
      "--------------------------------------------------\n",
      "BO STEP:  2\n",
      "--------------------------------------------------\n",
      "Candidate  0 tensor([[0.4716, 0.7473, 0.3771, 0.6950, 0.6345, 0.0048]]) tensor([-0.0495], grad_fn=<NegBackward>)\n",
      "Candidate  1 tensor([[0.5548, 0.4156, 0.6609, 0.3176, 0.8618, 0.4048]]) tensor([-2.3318e-07], grad_fn=<NegBackward>)\n",
      "Candidate  2 tensor([[0.6264, 0.2422, 0.3891, 0.3536, 0.6927, 0.6410]]) tensor([-1.1729e-08], grad_fn=<NegBackward>)\n",
      "Candidate  3 tensor([[0.5142, 0.5864, 0.9196, 0.1343, 0.6968, 0.1487]]) tensor([-3.1561e-07], grad_fn=<NegBackward>)\n",
      "Candidate  4 tensor([[0.1620, 0.7981, 0.6246, 0.0080, 0.1313, 0.6833]]) tensor([1.5708e-08], grad_fn=<NegBackward>)\n",
      "Result:  tensor([[0.4716, 0.7473, 0.3771, 0.6950, 0.6345, 0.0048]]) tensor([-0.0495], grad_fn=<NegBackward>)\n",
      "--------------------------------------------------\n",
      "BO STEP:  3\n",
      "--------------------------------------------------\n",
      "Candidate  0 tensor([[0.4714, 0.7496, 0.3761, 0.6949, 0.6322, 0.0048]]) tensor([-0.0455], grad_fn=<NegBackward>)\n",
      "Candidate  1 tensor([[0.0399, 0.5942, 0.8977, 0.9415, 0.5368, 0.9562]]) tensor([1.8590e-08], grad_fn=<NegBackward>)\n",
      "Candidate  2 tensor([[0.3802, 0.3375, 0.2495, 0.6317, 0.7838, 0.6530]]) tensor([-2.0604e-07], grad_fn=<NegBackward>)\n",
      "Candidate  3 tensor([[0.0468, 0.1216, 0.9841, 0.1309, 0.4972, 0.5667]]) tensor([-1.6134e-06], grad_fn=<NegBackward>)\n",
      "Candidate  4 tensor([[0.1475, 0.4035, 0.7612, 0.1776, 0.2355, 0.9847]]) tensor([-5.9259e-07], grad_fn=<NegBackward>)\n",
      "Result:  tensor([[0.4714, 0.7496, 0.3761, 0.6949, 0.6322, 0.0048]]) tensor([-0.0455], grad_fn=<NegBackward>)\n",
      "--------------------------------------------------\n",
      "BO STEP:  4\n",
      "--------------------------------------------------\n",
      "Candidate  0 tensor([[0.4689, 0.7495, 0.3767, 0.6959, 0.6314, 0.0047]]) tensor([-0.0269], grad_fn=<NegBackward>)\n",
      "Candidate  1 tensor([[0.1439, 0.0811, 0.0645, 0.0467, 0.4334, 0.4209]]) tensor([-1.6878e-06], grad_fn=<NegBackward>)\n",
      "Candidate  2 tensor([[0.3438, 0.9034, 0.7518, 0.1646, 0.1382, 0.9325]]) tensor([-4.5895e-06], grad_fn=<NegBackward>)\n",
      "Candidate  3 tensor([[0.3265, 0.0547, 0.3624, 0.4313, 0.6296, 0.4291]]) tensor([-4.4664e-06], grad_fn=<NegBackward>)\n",
      "Candidate  4 tensor([[0.5806, 0.7834, 0.4417, 0.9674, 0.0439, 0.5275]]) tensor([-3.5706e-08], grad_fn=<NegBackward>)\n",
      "Result:  tensor([[0.4689, 0.7495, 0.3767, 0.6959, 0.6314, 0.0047]]) tensor([-0.0269], grad_fn=<NegBackward>)\n",
      "--------------------------------------------------\n",
      "BO STEP:  5\n",
      "--------------------------------------------------\n",
      "Candidate  0 tensor([[0.4638, 0.7496, 0.3790, 0.6883, 0.6299, 0.0047]]) tensor([-0.0573], grad_fn=<NegBackward>)\n",
      "Candidate  1 tensor([[0.4543, 0.9238, 0.8700, 0.0418, 0.9724, 0.3558]]) tensor([-1.6781e-07], grad_fn=<NegBackward>)\n",
      "Candidate  2 tensor([[0.6707, 0.2688, 0.4526, 0.5104, 0.0509, 0.9852]]) tensor([-5.4035e-08], grad_fn=<NegBackward>)\n",
      "Candidate  3 tensor([[0.6574, 0.6608, 0.9284, 0.5677, 0.9112, 0.5729]]) tensor([-1.1322e-06], grad_fn=<NegBackward>)\n",
      "Candidate  4 tensor([[0.4568, 0.7855, 0.3511, 0.2366, 0.9278, 0.7620]]) tensor([-0.0002], grad_fn=<NegBackward>)\n",
      "Result:  tensor([[0.4638, 0.7496, 0.3790, 0.6883, 0.6299, 0.0047]]) tensor([-0.0573], grad_fn=<NegBackward>)\n",
      "--------------------------------------------------\n",
      "BO STEP:  6\n",
      "--------------------------------------------------\n",
      "Candidate  0 tensor([[0.4675, 0.7666, 0.3623, 0.6872, 0.6138, 0.0043]]) tensor([-0.0234], grad_fn=<NegBackward>)\n",
      "Candidate  1 tensor([[0.4649, 0.7618, 0.5661, 0.1034, 0.8592, 0.5494]]) tensor([-8.8308e-10], grad_fn=<NegBackward>)\n",
      "Candidate  2 tensor([[0.0147, 0.7273, 0.5440, 0.6347, 0.8733, 0.0688]]) tensor([-9.2781e-07], grad_fn=<NegBackward>)\n",
      "Candidate  3 tensor([[0.7907, 0.2352, 0.7174, 0.6914, 0.9383, 0.3275]]) tensor([-1.0236e-13], grad_fn=<NegBackward>)\n",
      "Candidate  4 tensor([[0.0392, 0.0372, 0.6939, 0.0700, 0.6344, 0.1937]]) tensor([-7.6896e-07], grad_fn=<NegBackward>)\n",
      "Result:  tensor([[0.4675, 0.7666, 0.3623, 0.6872, 0.6138, 0.0043]]) tensor([-0.0234], grad_fn=<NegBackward>)\n",
      "--------------------------------------------------\n",
      "BO STEP:  7\n",
      "--------------------------------------------------\n",
      "Candidate  0 tensor([[0.4596, 0.7821, 0.3425, 0.6825, 0.5992, 0.0039]]) tensor([-0.0135], grad_fn=<NegBackward>)\n",
      "Candidate  1 tensor([[0.9104, 0.0943, 0.8279, 0.4582, 0.0460, 0.2956]]) tensor([-6.3499e-10], grad_fn=<NegBackward>)\n",
      "Candidate  2 tensor([[0.0043, 0.5726, 0.3534, 0.3602, 0.5278, 0.0998]]) tensor([-1.0142e-18], grad_fn=<NegBackward>)\n",
      "Candidate  3 tensor([[0.8512, 0.7090, 0.8259, 0.6047, 0.3766, 0.1266]]) tensor([-1.1771e-07], grad_fn=<NegBackward>)\n",
      "Candidate  4 tensor([[0.3445, 0.8177, 0.9331, 0.3869, 0.5343, 0.7611]]) tensor([-2.5450e-08], grad_fn=<NegBackward>)\n",
      "Result:  tensor([[0.4596, 0.7821, 0.3425, 0.6825, 0.5992, 0.0039]]) tensor([-0.0135], grad_fn=<NegBackward>)\n",
      "--------------------------------------------------\n",
      "BO STEP:  8\n",
      "--------------------------------------------------\n",
      "Candidate  0 tensor([[0.4454, 0.7956, 0.3269, 0.6740, 0.5849, 0.0036]]) tensor([-0.0228], grad_fn=<NegBackward>)\n",
      "Candidate  1 tensor([[0.2414, 0.1501, 0.1408, 0.6040, 0.7482, 0.2264]]) tensor([-1.3092e-08], grad_fn=<NegBackward>)\n",
      "Candidate  2 tensor([[0.1750, 0.0963, 0.5529, 0.5219, 0.4737, 0.9640]]) tensor([2.2807e-08], grad_fn=<NegBackward>)\n",
      "Candidate  3 tensor([[0.6903, 0.6017, 0.9842, 0.5127, 0.0187, 0.8184]]) tensor([8.1208e-09], grad_fn=<NegBackward>)\n",
      "Candidate  4 tensor([[0.0851, 0.8669, 0.0413, 0.5494, 0.3905, 0.5187]]) tensor([-2.0321e-17], grad_fn=<NegBackward>)\n",
      "Result:  tensor([[0.4454, 0.7956, 0.3269, 0.6740, 0.5849, 0.0036]]) tensor([-0.0228], grad_fn=<NegBackward>)\n",
      "--------------------------------------------------\n",
      "BO STEP:  9\n",
      "--------------------------------------------------\n",
      "Candidate  0 tensor([[0.4284, 0.8099, 0.3098, 0.6654, 0.5719, 0.0032]]) tensor([-0.0142], grad_fn=<NegBackward>)\n",
      "Candidate  1 tensor([[0.7820, 0.5914, 0.8737, 0.6748, 0.2622, 0.7085]]) tensor([-3.1590e-09], grad_fn=<NegBackward>)\n",
      "Candidate  2 tensor([[0.5019, 0.4694, 0.3076, 0.1224, 0.4999, 0.4744]]) tensor([-1.4657e-06], grad_fn=<NegBackward>)\n",
      "Candidate  3 tensor([[0.9318, 0.4162, 0.6478, 0.7147, 0.6996, 0.7605]]) tensor([-1.2095e-12], grad_fn=<NegBackward>)\n",
      "Candidate  4 tensor([[0.6579, 0.1624, 0.9898, 0.2617, 0.2940, 0.2452]]) tensor([-5.4489e-09], grad_fn=<NegBackward>)\n",
      "Result:  tensor([[0.4284, 0.8099, 0.3098, 0.6654, 0.5719, 0.0032]]) tensor([-0.0142], grad_fn=<NegBackward>)\n",
      "--------------------------------------------------\n",
      "BO STEP:  10\n",
      "--------------------------------------------------\n",
      "Candidate  0 tensor([[0.4124, 0.8216, 0.2913, 0.6577, 0.5551, 0.0030]]) tensor([-0.0316], grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate  1 tensor([[0.1821, 0.4349, 0.3009, 0.9712, 0.5084, 0.3888]]) tensor([-8.5361e-07], grad_fn=<NegBackward>)\n",
      "Candidate  2 tensor([[0.2149, 0.9227, 0.0193, 0.3689, 0.6019, 0.4095]]) tensor([-4.5501e-05], grad_fn=<NegBackward>)\n",
      "Candidate  3 tensor([[0.2168, 0.1710, 0.5498, 0.0197, 0.6153, 0.5227]]) tensor([-8.9280e-09], grad_fn=<NegBackward>)\n",
      "Candidate  4 tensor([[0.3865, 0.5748, 0.1963, 0.6617, 0.4324, 0.1784]]) tensor([-3.6837e-07], grad_fn=<NegBackward>)\n",
      "Result:  tensor([[0.4124, 0.8216, 0.2913, 0.6577, 0.5551, 0.0030]]) tensor([-0.0316], grad_fn=<NegBackward>)\n",
      "--------------------------------------------------\n",
      "BO STEP:  11\n",
      "--------------------------------------------------\n",
      "Candidate  0 tensor([[0.4019, 0.8323, 0.2728, 0.6475, 0.5393, 0.0027]]) tensor([-0.0323], grad_fn=<NegBackward>)\n",
      "Candidate  1 tensor([[0.5433, 0.5827, 0.6691, 0.6629, 0.0451, 0.3136]]) tensor([-6.8619e-10], grad_fn=<NegBackward>)\n",
      "Candidate  2 tensor([[0.0061, 0.9186, 0.0090, 0.3332, 0.5563, 0.1864]]) tensor([-1.1333e-06], grad_fn=<NegBackward>)\n",
      "Candidate  3 tensor([[0.5714, 0.0816, 0.2403, 0.6549, 0.6312, 0.0947]]) tensor([-3.8545e-05], grad_fn=<NegBackward>)\n",
      "Candidate  4 tensor([[0.1020, 0.8532, 0.3773, 0.1947, 0.0087, 0.5892]]) tensor([-1.5904e-10], grad_fn=<NegBackward>)\n",
      "Result:  tensor([[0.4019, 0.8323, 0.2728, 0.6475, 0.5393, 0.0027]]) tensor([-0.0323], grad_fn=<NegBackward>)\n",
      "--------------------------------------------------\n",
      "BO STEP:  12\n",
      "--------------------------------------------------\n",
      "Candidate  0 tensor([[0.3960, 0.8430, 0.2550, 0.6406, 0.5245, 0.0025]]) tensor([-0.0313], grad_fn=<NegBackward>)\n",
      "Candidate  1 tensor([[0.7302, 0.8027, 0.6996, 0.8777, 0.4300, 0.1300]]) tensor([-2.9271e-17], grad_fn=<NegBackward>)\n",
      "Candidate  2 tensor([[0.0687, 0.9245, 0.3343, 0.1232, 0.6216, 0.2252]]) tensor([-1.0594e-13], grad_fn=<NegBackward>)\n",
      "Candidate  3 tensor([[0.1957, 0.0957, 0.0406, 0.4351, 0.8679, 0.2325]]) tensor([1.8100e-08], grad_fn=<NegBackward>)\n",
      "Candidate  4 tensor([[0.7033, 0.0801, 0.9735, 0.3347, 0.0777, 0.1067]]) tensor([-9.0155e-11], grad_fn=<NegBackward>)\n",
      "Result:  tensor([[0.3960, 0.8430, 0.2550, 0.6406, 0.5245, 0.0025]]) tensor([-0.0313], grad_fn=<NegBackward>)\n",
      "--------------------------------------------------\n",
      "BO STEP:  13\n",
      "--------------------------------------------------\n",
      "Candidate  0 tensor([[0.3994, 0.8531, 0.2377, 0.6340, 0.5074, 0.0023]]) tensor([-0.0282], grad_fn=<NegBackward>)\n",
      "Candidate  1 tensor([[0.9026, 0.0376, 0.5947, 0.3640, 0.2749, 0.3828]]) tensor([-9.6721e-16], grad_fn=<NegBackward>)\n",
      "Candidate  2 tensor([[0.5726, 0.0619, 0.1247, 0.2574, 0.2641, 0.1799]]) tensor([-2.0842e-06], grad_fn=<NegBackward>)\n",
      "Candidate  3 tensor([[0.9927, 0.7196, 0.6277, 0.0443, 0.2476, 0.7007]]) tensor([-2.6615e-09], grad_fn=<NegBackward>)\n",
      "Candidate  4 tensor([[0.1249, 0.3417, 0.4588, 0.4536, 0.2891, 0.6383]]) tensor([-2.6945e-14], grad_fn=<NegBackward>)\n",
      "Result:  tensor([[0.3994, 0.8531, 0.2377, 0.6340, 0.5074, 0.0023]]) tensor([-0.0282], grad_fn=<NegBackward>)\n",
      "--------------------------------------------------\n",
      "BO STEP:  14\n",
      "--------------------------------------------------\n",
      "Candidate  0 tensor([[0.4051, 0.8618, 0.2216, 0.6203, 0.4951, 0.0021]]) tensor([-0.0180], grad_fn=<NegBackward>)\n",
      "Candidate  1 tensor([[0.6658, 0.3505, 0.6131, 0.5132, 0.9389, 0.6952]]) tensor([-5.4816e-15], grad_fn=<NegBackward>)\n",
      "Candidate  2 tensor([[0.9675, 0.7398, 0.5212, 0.6452, 0.1741, 0.6023]]) tensor([-3.5726e-21], grad_fn=<NegBackward>)\n",
      "Candidate  3 tensor([[0.2571, 0.7693, 0.2147, 0.0217, 0.1235, 0.8494]]) tensor([-1.9976e-08], grad_fn=<NegBackward>)\n",
      "Candidate  4 tensor([[0.6181, 0.0625, 0.3051, 0.8764, 0.8538, 0.9340]]) tensor([-2.9748e-09], grad_fn=<NegBackward>)\n",
      "Result:  tensor([[0.4051, 0.8618, 0.2216, 0.6203, 0.4951, 0.0021]]) tensor([-0.0180], grad_fn=<NegBackward>)\n",
      "--------------------------------------------------\n",
      "BO STEP:  15\n",
      "--------------------------------------------------\n",
      "Candidate  0 tensor([[0.4076, 0.8712, 0.2067, 0.6063, 0.4905, 0.0019]]) tensor([-0.0260], grad_fn=<NegBackward>)\n",
      "Candidate  1 tensor([[0.7485, 0.5185, 0.5542, 0.6082, 0.8653, 0.8547]]) tensor([-1.3099e-25], grad_fn=<NegBackward>)\n",
      "Candidate  2 tensor([[3.8313e-01, 4.5713e-01, 4.9204e-04, 4.4504e-01, 6.2931e-01, 6.7685e-01]]) tensor([-4.7243e-06], grad_fn=<NegBackward>)\n",
      "Candidate  3 tensor([[0.9113, 0.9974, 0.0653, 0.1843, 0.8486, 0.6490]]) tensor([-3.1139e-17], grad_fn=<NegBackward>)\n",
      "Candidate  4 tensor([[0.8459, 0.1146, 0.2385, 0.6005, 0.9281, 0.2946]]) tensor([-2.4831e-42], grad_fn=<NegBackward>)\n",
      "Result:  tensor([[0.4076, 0.8712, 0.2067, 0.6063, 0.4905, 0.0019]]) tensor([-0.0260], grad_fn=<NegBackward>)\n",
      "--------------------------------------------------\n",
      "BO STEP:  16\n",
      "--------------------------------------------------\n",
      "Candidate  0 tensor([[0.4052, 0.8807, 0.1927, 0.5938, 0.4988, 0.0018]]) tensor([-0.0237], grad_fn=<NegBackward>)\n",
      "Candidate  1 tensor([[0.2693, 0.3880, 0.3742, 0.2487, 0.2238, 0.7646]]) tensor([-5.0845e-19], grad_fn=<NegBackward>)\n",
      "Candidate  2 tensor([[0.0112, 0.8014, 0.0264, 0.5033, 0.6662, 0.4300]]) tensor([-3.8089e-08], grad_fn=<NegBackward>)\n",
      "Candidate  3 tensor([[0.7052, 0.5703, 0.6535, 0.6448, 0.1430, 0.9334]]) tensor([-6.0329e-21], grad_fn=<NegBackward>)\n",
      "Candidate  4 tensor([[0.7827, 0.9551, 0.9656, 0.1124, 0.3608, 0.6570]]) tensor([-1.1928e-28], grad_fn=<NegBackward>)\n",
      "Result:  tensor([[0.4052, 0.8807, 0.1927, 0.5938, 0.4988, 0.0018]]) tensor([-0.0237], grad_fn=<NegBackward>)\n",
      "--------------------------------------------------\n",
      "BO STEP:  17\n",
      "--------------------------------------------------\n",
      "Candidate  0 tensor([[0.4077, 0.8890, 0.1804, 0.5830, 0.5165, 0.0016]]) tensor([-0.0298], grad_fn=<NegBackward>)\n",
      "Candidate  1 tensor([[0.7378, 0.7568, 0.2870, 0.3992, 0.6863, 0.7002]]) tensor([-4.5513e-23], grad_fn=<NegBackward>)\n",
      "Candidate  2 tensor([[0.1104, 0.3417, 0.3471, 0.1170, 0.0540, 0.2639]]) tensor([-4.5390e-08], grad_fn=<NegBackward>)\n",
      "Candidate  3 tensor([[0.7630, 0.9640, 0.8030, 0.9729, 0.4968, 0.9861]]) tensor([-1.5466e-10], grad_fn=<NegBackward>)\n",
      "Candidate  4 tensor([[9.0541e-02, 2.4679e-01, 5.5523e-01, 8.4358e-01, 2.1272e-04, 2.8433e-01]]) tensor([-3.2014e-10], grad_fn=<NegBackward>)\n",
      "Result:  tensor([[0.4077, 0.8890, 0.1804, 0.5830, 0.5165, 0.0016]]) tensor([-0.0298], grad_fn=<NegBackward>)\n",
      "--------------------------------------------------\n",
      "BO STEP:  18\n",
      "--------------------------------------------------\n",
      "Candidate  0 tensor([[0.4093, 0.8947, 0.1700, 0.5731, 0.5227, 0.0015]]) tensor([-0.0258], grad_fn=<NegBackward>)\n",
      "Candidate  1 tensor([[0.0485, 0.3174, 0.2205, 0.6505, 0.4007, 0.7536]]) tensor([-2.6111e-16], grad_fn=<NegBackward>)\n",
      "Candidate  2 tensor([[0.7647, 0.0771, 0.4438, 0.7254, 0.7238, 0.8062]]) tensor([-6.3354e-33], grad_fn=<NegBackward>)\n",
      "Candidate  3 tensor([[0.3403, 0.4562, 0.3526, 0.7419, 0.2708, 0.2291]]) tensor([-1.5844e-09], grad_fn=<NegBackward>)\n",
      "Candidate  4 tensor([[0.6901, 0.5682, 0.0370, 0.3476, 0.4514, 0.9520]]) tensor([-1.4982e-36], grad_fn=<NegBackward>)\n",
      "Result:  tensor([[0.4093, 0.8947, 0.1700, 0.5731, 0.5227, 0.0015]]) tensor([-0.0258], grad_fn=<NegBackward>)\n",
      "--------------------------------------------------\n",
      "BO STEP:  19\n",
      "--------------------------------------------------\n",
      "Candidate  0 tensor([[0.3995, 0.8956, 0.1702, 0.5850, 0.5056, 0.0015]]) tensor([-0.0158], grad_fn=<NegBackward>)\n",
      "Candidate  1 tensor([[0.1873, 0.6911, 0.4191, 0.0189, 0.9693, 0.4425]]) tensor([-8.1502e-13], grad_fn=<NegBackward>)\n",
      "Candidate  2 tensor([[0.5843, 0.1982, 0.3464, 0.0790, 0.5854, 0.2983]]) tensor([-3.7807e-09], grad_fn=<NegBackward>)\n",
      "Candidate  3 tensor([[0.0111, 0.6306, 0.1214, 0.8312, 0.0180, 0.5695]]) tensor([-2.3467e-07], grad_fn=<NegBackward>)\n",
      "Candidate  4 tensor([[0.7106, 0.2116, 0.2482, 0.0132, 0.7076, 0.7873]]) tensor([-4.7203e-25], grad_fn=<NegBackward>)\n",
      "Result:  tensor([[0.3995, 0.8956, 0.1702, 0.5850, 0.5056, 0.0015]]) tensor([-0.0158], grad_fn=<NegBackward>)\n"
     ]
    }
   ],
   "source": [
    "set_random_seed(333)\n",
    "\n",
    "pyro.clear_param_store()\n",
    "gp_model_svi = gp.models.GPRegression(X_train, Y_train, gp.kernels.Matern52(input_dim=6, lengthscale=torch.ones(6)))\n",
    "\n",
    "# Set priors\n",
    "gp_model_svi.kernel.lengthscale = pyro.nn.PyroSample(dist.LogNormal(0, 1).expand([6]).to_event())\n",
    "gp_model_svi.kernel.variance = pyro.nn.PyroSample(dist.LogNormal(0, 1))\n",
    "gp_model_svi.noise = pyro.nn.PyroSample(dist.LogNormal(0, 1))\n",
    "\n",
    "# Set guides\n",
    "gp_model_svi.kernel.autoguide(\"lengthscale\", dist.Normal)\n",
    "gp_model_svi.kernel.autoguide(\"variance\", dist.Normal)\n",
    "gp_model_svi.autoguide(\"noise\", dist.Normal)\n",
    "\n",
    "# optimise\n",
    "optimizer = torch.optim.Adam(gp_model_svi.parameters(), lr=0.005)\n",
    "loss_fn = pyro.infer.TraceMeanField_ELBO().differentiable_loss\n",
    "losses = gp.util.train(gp_model_svi, optimizer, loss_fn, num_steps=2000)\n",
    "\n",
    "bo_steps = 20\n",
    "\n",
    "for i in range(bo_steps):\n",
    "    print(\"-\"*50)\n",
    "    print(\"BO STEP: \", i)\n",
    "    print(\"-\"*50)\n",
    "    \n",
    "    gp_model_svi_ = copy.copy(gp_model_svi)\n",
    "    \n",
    "    xmin, xcans = next_x(gp_model_svi)\n",
    "    \n",
    "    update_posterior(gp_model_svi, xmin, svi_mode=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
