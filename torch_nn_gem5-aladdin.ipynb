{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the grid search results from the simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"gem5-aladdin_data/stencil_stencil3d_results.csv\"\n",
    "results_df = pd.read_csv(file_path, delimiter=\",\").drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tlb_page_size', 'tlb_entries', 'tlb_assoc', 'cycle_time',\n",
       "       'tlb_max_outstanding_walks', 'tlb_miss_latency', 'cache_line_sz',\n",
       "       'cache_assoc', 'cache_queue_size', 'tlb_hit_latency', 'pipelined_dma',\n",
       "       'cache_size', 'pipelining', 'cache_hit_latency', 'cache_bandwidth',\n",
       "       'tlb_bandwidth', 'success', 'cycle', 'power', 'area'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data_np = results_df[['tlb_page_size', 'tlb_entries', 'tlb_assoc', 'cycle_time',\n",
    "       'tlb_max_outstanding_walks', 'tlb_miss_latency', 'cache_line_sz',\n",
    "       'cache_assoc', 'cache_queue_size', 'tlb_hit_latency', 'pipelined_dma',\n",
    "       'cache_size', 'pipelining', 'cache_hit_latency', 'cache_bandwidth',\n",
    "       'tlb_bandwidth']].values.astype(np.float32)\n",
    "\n",
    "y_data_np = results_df['power'].values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_np, X_test_np, y_train_np, y_test_np = train_test_split(X_data_np, \n",
    "                                                                y_data_np, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting numpy arrays to torch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train_np)\n",
    "X_test = torch.tensor(X_test_np)\n",
    "y_train = torch.tensor(y_train_np)\n",
    "y_test = torch.tensor(y_test_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network\n",
    "\n",
    "A simple feed forward neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(FFNet, self).__init__()\n",
    "        \n",
    "        self.input_ch = 16\n",
    "        self.output_ch = 1\n",
    "        \n",
    "        ######## Hidden layers ########\n",
    "        \n",
    "        #   linear functions\n",
    "        self.lf1_output_ch = 100\n",
    "        self.lf1 = nn.Linear(self.input_ch, self.lf1_output_ch)\n",
    "        \n",
    "#         self.lf2_output_ch = 100\n",
    "#         self.lf2 = nn.Linear(self.lf1_output_ch, self.lf2_output_ch)\n",
    "        \n",
    "        self.lf3_output_ch = 50\n",
    "        self.lf3 = nn.Linear(self.lf1_output_ch, self.lf3_output_ch)\n",
    "        \n",
    "#         self.lf4_output_ch = 50\n",
    "#         self.lf4 = nn.Linear(self.lf3_output_ch, self.lf4_output_ch)\n",
    "        \n",
    "#         self.lf5_output_ch = 50\n",
    "#         self.lf5 = nn.Linear(self.lf4_output_ch, self.lf5_output_ch)\n",
    "        \n",
    "#         self.lf6_output_ch = 50\n",
    "#         self.lf6 = nn.Linear(self.lf5_output_ch, self.lf6_output_ch)\n",
    "        \n",
    "#         self.lf7_output_ch = 25\n",
    "#         self.lf7 = nn.Linear(self.lf6_output_ch, self.lf7_output_ch)\n",
    "        \n",
    "#         self.lf8_output_ch = 25\n",
    "#         self.lf8 = nn.Linear(self.lf7_output_ch, self.lf8_output_ch)\n",
    "        \n",
    "#         self.lf9_output_ch = 25\n",
    "#         self.lf9 = nn.Linear(self.lf8_output_ch, self.lf9_output_ch)\n",
    "        \n",
    "        self.lf10_output_ch = 10\n",
    "        self.lf10 = nn.Linear(self.lf3_output_ch, self.lf10_output_ch)\n",
    "        \n",
    "        #   linear function\n",
    "        self.lff = nn.Linear(self.lf10_output_ch, self.output_ch)\n",
    "        \n",
    "        ######## Functions ########\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \n",
    "        out = self.lf1(X)\n",
    "        out = self.relu(out)\n",
    "        out = self.lf3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.lf10(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.lff(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffnet_model = FFNet()\n",
    "optimizer = torch.optim.Adam(ffnet_model.parameters(), lr=0.00001)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 0.001%: train loss: 233448.421875\n",
      "Epoch 10000 10.0%: train loss: 86.77014923095703\n",
      "Epoch 20000 20.0%: train loss: 84.00674438476562\n",
      "Epoch 30000 30.0%: train loss: 81.21456909179688\n",
      "Epoch 40000 40.0%: train loss: 77.97526550292969\n",
      "Epoch 50000 50.0%: train loss: 74.84622955322266\n",
      "Epoch 60000 60.0%: train loss: 72.31035614013672\n",
      "Epoch 70000 70.0%: train loss: 70.0422134399414\n",
      "Epoch 80000 80.0%: train loss: 67.69535064697266\n",
      "Epoch 90000 90.0%: train loss: 65.37538146972656\n",
      "Epoch 100000 100.0%: train loss: 62.86763000488281\n"
     ]
    }
   ],
   "source": [
    "# Sets the module in training mode.\n",
    "ffnet_model.train()\n",
    "\n",
    "num_epochs = 100000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    y_pred = ffnet_model(X_train)\n",
    "    \n",
    "    # Compute Loss\n",
    "    loss = criterion(y_pred.squeeze(), y_train)\n",
    "    \n",
    "    if ((epoch+1) % ((num_epochs) * 0.1) == 0) or (epoch == 0):\n",
    "        print('Epoch {} {}%: train loss: {}'.format(epoch+1, (epoch+1)/num_epochs*100,loss.item()))\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss after Training 77.04769897460938\n"
     ]
    }
   ],
   "source": [
    "# Sets the module in evulation mode.\n",
    "ffnet_model.eval()\n",
    "\n",
    "y_pred = ffnet_model(X_test)\n",
    "after_train = criterion(y_pred.squeeze(), y_test) \n",
    "print('Test loss after Training' , after_train.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241 tensor(8.8664, grad_fn=<SelectBackward>) tensor(8.3212)\n"
     ]
    }
   ],
   "source": [
    "from random import randrange\n",
    "num = randrange(len(y_test))\n",
    "print(num, y_pred.squeeze()[num], y_test[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
