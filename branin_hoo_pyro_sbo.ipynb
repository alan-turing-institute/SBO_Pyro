{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structured Bayesian Optimisation with Pyro\n",
    "\n",
    "Goal: apply Structured Bayesian Optimisation (SBO) strategy to minimize Branin-Hoo function with pyro.\n",
    "\n",
    "Based on: \n",
    "- branin_hoo_pyro_semiparam_brooks.ipynb\n",
    "- branin_hoo_pyro_bo.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions import constraints, transform_to\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.contrib.gp as gp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.__version__)\n",
    "print(pyro.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const_x1_min = -5\n",
    "const_x1_max = 10\n",
    "\n",
    "const_x2_min = 0\n",
    "const_x2_max = 15\n",
    "\n",
    "def branin_hoo(x):\n",
    "    \"\"\" Compute Branin-Hoo function for fixed constants \"\"\"\n",
    "    a = 1.0\n",
    "    b = 5.1 / (4 * np.pi**2)\n",
    "    c = 5.0 / np.pi\n",
    "    r = 6.0\n",
    "    s = 10.0\n",
    "    t = 1.0 / (8 * np.pi)\n",
    "    x1 = x[...,0]\n",
    "    x2 = x[...,1]\n",
    "    return a * (x2 - b*x1**2 + c*x1 - r)**2 + s*(1 - t)*torch.cos(x1) + s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_function(f, n_points=100):\n",
    "    XX, YY = np.meshgrid(np.linspace(-5, 10, n_points), np.linspace(0, 15, n_points))\n",
    "    ZZ = f(torch.FloatTensor(np.stack([XX.ravel(), YY.ravel()]).T))\n",
    "    plt.imshow(ZZ.reshape(n_points, n_points));\n",
    "    plt.xticks(np.linspace(0, n_points, 6), np.linspace(-5, 10, 6))\n",
    "    plt.yticks(np.linspace(0, n_points, 6), np.linspace(0, 15, 6))\n",
    "    plt.xlabel('x1')\n",
    "    plt.ylabel('x2')\n",
    "    plt.set_cmap('jet')\n",
    "    plt.colorbar()\n",
    "    plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_function(branin_hoo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial (train) data\n",
    "\n",
    "Generating random training points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.random.manual_seed(555)\n",
    "\n",
    "N_points = 10\n",
    "X = torch.rand(N_points, 2)*15 + torch.FloatTensor([-5, 0])\n",
    "y = branin_hoo(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training points: \", X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parametric model in pyro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matching the parametric function used in BOAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parametric_fn(X, alpha, beta, gamma):\n",
    "    x1 = X[...,0]\n",
    "    x2 = X[...,1]\n",
    "    return alpha * torch.cos(x1) + beta*torch.pow(x1, 4) + torch.pow(x2, 2) + gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi parametric model as implemented by Brooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.clear_param_store()\n",
    "\n",
    "class SemiParametricModel(nn.Module):\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Store data\n",
    "        D = X.shape[-1]\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "        # Define parameters for parametric model\n",
    "        # TODO: I couldn't figure out how to do this using `pyro.param`, so instead\n",
    "        #       I am using `nn.Parameter`. This is annoying, because now constraints\n",
    "        #       need to be handled manually, using the properties below\n",
    "        self._mu_a = nn.Parameter(torch.zeros(1))\n",
    "        self._mu_b = nn.Parameter(torch.zeros(1))\n",
    "        self._mu_c = nn.Parameter(torch.zeros(1))\n",
    "        self._sd_a = nn.Parameter(torch.zeros(1))\n",
    "        self._sd_b = nn.Parameter(torch.zeros(1))\n",
    "        self._sd_c = nn.Parameter(torch.zeros(1))\n",
    "        \n",
    "        self._mu_transform = transform_to(constraints.interval(0, 20))\n",
    "        self._sd_transform = transform_to(constraints.positive)\n",
    "\n",
    "        # Define GP regressor (leave the data arguments empty for now)\n",
    "        self.gp = gp.models.GPRegression(torch.empty((0, D)), torch.empty((0,)),\n",
    "                                         kernel=gp.kernels.Matern52(input_dim=D, lengthscale=torch.ones(D)))\n",
    "                \n",
    "        # Set priors for GP (these are the values used in the semiparametric BOAT model, which assumes noiseless GP)\n",
    "        self.gp.kernel.set_prior(\"lengthscale\", dist.LogNormal(0.0, 15.0).expand((2,)).to_event(1))\n",
    "        self.gp.kernel.set_prior(\"variance\", dist.Uniform(0.0, 20.0))\n",
    "        self.gp.set_prior(\"noise\", dist.Uniform(0.0, 1.0))\n",
    "\n",
    "        # Set guides for GP\n",
    "        self.gp.kernel.autoguide(\"lengthscale\", dist.Normal)\n",
    "        self.gp.kernel.autoguide(\"variance\", dist.Normal)\n",
    "        self.gp.autoguide(\"noise\", dist.Normal)\n",
    "        \n",
    "    @property\n",
    "    def mu_a(self): return self._mu_transform(self._mu_a)\n",
    "\n",
    "    @property\n",
    "    def mu_b(self): return self._mu_transform(self._mu_b)\n",
    "\n",
    "    @property\n",
    "    def mu_c(self): return self._mu_transform(self._mu_c)\n",
    "\n",
    "    @property\n",
    "    def sd_a(self): return self._sd_transform(self._sd_a)\n",
    "\n",
    "    @property\n",
    "    def sd_b(self): return self._sd_transform(self._sd_b)\n",
    "    \n",
    "    @property\n",
    "    def sd_c(self): return self._sd_transform(self._sd_c)\n",
    "    \n",
    "    def guide(self):\n",
    "        self.gp.guide()\n",
    "        alpha = pyro.sample('alpha', dist.Normal(self.mu_a, self.sd_a))\n",
    "        beta = pyro.sample('beta', dist.Normal(self.mu_b, self.sd_b))\n",
    "        gamma = pyro.sample('gamma', dist.Normal(self.mu_c, self.sd_c))\n",
    "        return alpha, beta, gamma\n",
    "\n",
    "    def model(self):\n",
    "        alpha = pyro.sample('alpha', dist.Uniform(0, 20))\n",
    "        beta = pyro.sample('beta', dist.Uniform(0, 20))\n",
    "        gamma = pyro.sample('gamma', dist.Uniform(0, 20))\n",
    "        g = parametric_fn(self.X, alpha, beta, gamma)\n",
    "        residual = self.y - g\n",
    "        # update the GP to now model the residual from the parametric model\n",
    "        self.gp.set_data(self.X, residual)       \n",
    "        # call GP model function to actually make the observation\n",
    "        self.gp.model()\n",
    "        \n",
    "    def forward(self, X):\n",
    "        g = parametric_fn(X, *self.guide())        \n",
    "        mu, var = self.gp(X)\n",
    "        return g + mu, var\n",
    "    \n",
    "    def optimise_gp_params(self):\n",
    "        \n",
    "        # Optimising GP parameters\n",
    "        optimizer = torch.optim.Adam(self.gp.parameters(), lr=0.005)\n",
    "        loss_fn = pyro.infer.Trace_ELBO().differentiable_loss\n",
    "        num_steps = 5000\n",
    "        \n",
    "        for i in range(num_steps):\n",
    "            optimizer.zero_grad()\n",
    "            loss = loss_fn(self.gp.model, self.gp.guide)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "semi_parametric = SemiParametricModel(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "semi_parametric.gp.set_data(X, y)\n",
    "# Optimising GP parameters\n",
    "optimizer = torch.optim.Adam(semi_parametric.gp.parameters(), lr=0.005)\n",
    "loss_fn = pyro.infer.Trace_ELBO().differentiable_loss\n",
    "num_steps = 5000\n",
    "\n",
    "for i in range(num_steps):\n",
    "    optimizer.zero_grad()\n",
    "    loss = loss_fn(semi_parametric.gp.model, semi_parametric.gp.guide)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing SBO strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_steps=1000):\n",
    "    \n",
    "    param_opt = torch.optim.Adam(semi_parametric.parameters(recurse=False), lr=0.1)\n",
    "    gp_opt = torch.optim.Adam(semi_parametric.gp.parameters(), lr=0.005)\n",
    "    \n",
    "    loss_fn = pyro.infer.Trace_ELBO().differentiable_loss\n",
    "    \n",
    "    losses = []\n",
    "        \n",
    "    for i in range(num_steps):\n",
    "        gp_opt.zero_grad()\n",
    "        param_opt.zero_grad()\n",
    "        loss = loss_fn(semi_parametric.model, semi_parametric.guide)\n",
    "        loss.backward()\n",
    "        gp_opt.step()\n",
    "        param_opt.step()\n",
    "        losses.append(loss.item())\n",
    "    \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining acquisition function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acquisition_func(x):\n",
    "    kappa = 2.0\n",
    "    \n",
    "    mu, variance = semi_parametric(x)\n",
    "        \n",
    "    sigma = variance.sqrt()\n",
    "    \n",
    "    return mu - kappa * sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to find minimizing points for an acquisition function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:** Currently implated for the 2D example, needs to be made more general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_a_candidate(x_init):\n",
    "    \n",
    "    # Creating constrains\n",
    "    constraint_x1 = constraints.interval(const_x1_min, const_x1_max)\n",
    "    constraint_x2 = constraints.interval(const_x2_min, const_x2_max)\n",
    "    \n",
    "    # transform x_init to an unconstrained domain as we use an unconstrained optimizer\n",
    "    unconstrained_x1_init = transform_to(constraint_x1).inv(x_init[:, 0])\n",
    "    unconstrained_x2_init = transform_to(constraint_x2).inv(x_init[:, 1])\n",
    "    x_uncon_init = torch.stack((unconstrained_x1_init, unconstrained_x2_init), dim=1)\n",
    "    \n",
    "    x_uncon = x_uncon_init.clone().detach().requires_grad_(True)\n",
    "    \n",
    "    # unconstrained minimiser\n",
    "    minimizer = optim.Adam([x_uncon])\n",
    "\n",
    "    def closure():\n",
    "        minimizer.zero_grad()\n",
    "                \n",
    "        x1_tmp = transform_to(constraint_x1)(x_uncon[:, 0])\n",
    "        x2_tmp = transform_to(constraint_x2)(x_uncon[:, 1])\n",
    "        x = torch.stack((x1_tmp, x2_tmp), dim=1)\n",
    "        \n",
    "        y = acquisition_func(x)\n",
    "        \n",
    "        autograd.backward(x_uncon, autograd.grad(y, x_uncon))\n",
    "                \n",
    "        return y\n",
    "    \n",
    "    for _ in range(100):\n",
    "        minimizer.step(closure)\n",
    "   \n",
    "    # after finding a candidate in the unconstrained domain,\n",
    "    # convert it back to original domain.\n",
    "    x1_tmp = transform_to(constraint_x1)(x_uncon[:, 0])\n",
    "    x2_tmp = transform_to(constraint_x2)(x_uncon[:, 1])\n",
    "    \n",
    "    x = torch.stack((x1_tmp, x2_tmp), dim=1)\n",
    "    \n",
    "    return x.detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A single step of SBO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:** Currently implated for the 2D example, needs to be made more general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_x(num_candidates=5):\n",
    "    \n",
    "    candidates = []\n",
    "    values = []\n",
    "    \n",
    "    # take the last point as the first attempt\n",
    "    x_init = semi_parametric.X[-1:]\n",
    "    \n",
    "    for i in range(num_candidates):\n",
    "        \n",
    "        x = find_a_candidate(x_init)\n",
    "        y = acquisition_func(x)\n",
    "    \n",
    "        candidates.append(x)\n",
    "        values.append(y)\n",
    "        \n",
    "        # a new random attempt initial point\n",
    "        x_init = torch.stack((\n",
    "                x[:,0].new_empty(1).uniform_(const_x1_min, const_x1_max),\n",
    "                x[:,1].new_empty(1).uniform_(const_x2_min, const_x2_max)), dim=1)\n",
    "        \n",
    "    argmin = torch.min(torch.cat(values), dim=0)[1].item()\n",
    "        \n",
    "    return candidates[argmin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model():\n",
    "    plt.figure(figsize=(12,3)) \n",
    "    \n",
    "    # Acquisition function\n",
    "    plt.subplot(1,4,1)\n",
    "    plt.title(\"Acquisition\")\n",
    "    with torch.no_grad(): \n",
    "        plot_function(acquisition_func)\n",
    "\n",
    "    # Losses\n",
    "    plt.subplot(1,4,2)\n",
    "    plt.title(\"Losses\")\n",
    "    plt.semilogy(losses);\n",
    "\n",
    "    # Semi-param model mu\n",
    "    plt.subplot(1,4,3)\n",
    "    plt.title(\"Semi-param model $\\mu$\")\n",
    "    with torch.no_grad(): \n",
    "        plot_function(lambda X: semi_parametric(X)[0])\n",
    "\n",
    "    # Semi-param model sigma\n",
    "    plt.subplot(1,4,4)\n",
    "    plt.title(\"Semi-param model $\\sigma$\")\n",
    "    with torch.no_grad(): \n",
    "        plot_function(lambda X: semi_parametric(X)[1])\n",
    "\n",
    "    plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_posterior(x_new, viz_flag=False):\n",
    "    \n",
    "    # evaluate f at new point\n",
    "    bh_y = branin_hoo(x_new) \n",
    "        \n",
    "    # incorporate new evaluation\n",
    "    semi_parametric.X = torch.cat([semi_parametric.X, x_new]) \n",
    "    semi_parametric.y = torch.cat([semi_parametric.y, bh_y])\n",
    "    \n",
    "    losses = train()\n",
    "    \n",
    "    if viz_flag:\n",
    "        plot_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The SBO Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flag to visualise steps\n",
    "viz_flag = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "time_st = time.time()\n",
    "\n",
    "losses = train()\n",
    "\n",
    "if viz_flag:\n",
    "    plot_model()\n",
    "\n",
    "sbo_steps = 10\n",
    "\n",
    "for i in range(sbo_steps):\n",
    "    \n",
    "    xmin = next_x()\n",
    "    \n",
    "    print(\"Step SBO: \", i+1, \"new point: \", xmin)\n",
    "    \n",
    "    update_posterior(xmin, viz_flag)\n",
    "    \n",
    "print(\"Time: \", time.time() - time_st)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
